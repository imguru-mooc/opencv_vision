{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "코드 2-1"
      ],
      "metadata": {
        "id": "-cZcETQVP7aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1pO27YTida7yUIGaj3YxvPWa4gFZWhjhy"
      ],
      "metadata": {
        "id": "ea9cu7_9HR5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io9kjxGbR3qf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -U ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "import cv2, os, time, uuid\n",
        "from IPython.display import HTML, display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "\n",
        "video_path = \"/content/FA-50.mp4\"\n",
        "print(\"입력 영상:\", video_path)\n",
        "\n",
        "# === 2) 모델 로드 (YOLO11n) ===\n",
        "model = YOLO(\"yolo11n.pt\")  # 자동 다운로드\n",
        "\n",
        "# === 3) 추론 설정 ===\n",
        "CONF = 0.25           # 신뢰도 임계값\n",
        "DEVICE = 0            # GPU(0) 또는 'cpu'\n",
        "SHOW_EVERY = 30       # N프레임마다 코랩 셀에 미리보기 표시\n",
        "OUTPUT_PATH = f\"annotated_{Path(video_path).stem}.mp4\"\n",
        "\n",
        "# === 4) OpenCV로 프레임 단위 추론 & 시각화 ===\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(f\"비디오를 열 수 없습니다: {video_path}\")\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "w   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "writer = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (w, h))\n",
        "\n",
        "frame_idx = 0\n",
        "t0 = time.time()\n",
        "print(\"추론 시작...\")\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # YOLO 추론 (단일 프레임, numpy 입력)\n",
        "    results = model.predict(\n",
        "        source=frame,\n",
        "        conf=CONF,\n",
        "        device=DEVICE,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # 시각화 프레임 얻기 (BGR)\n",
        "    annotated = results[0].plot()\n",
        "\n",
        "    # 파일로 기록\n",
        "    writer.write(annotated)\n",
        "\n",
        "    # N 프레임마다 미리보기 (너무 자주 띄우면 느려질 수 있음)\n",
        "    if frame_idx % SHOW_EVERY == 0:\n",
        "        print(f\"preview frame #{frame_idx}\")\n",
        "        cv2_imshow(annotated)  # 코랩 전용 이미지 표시\n",
        "    frame_idx += 1\n",
        "\n",
        "cap.release()\n",
        "writer.release()\n",
        "elapsed = time.time() - t0\n",
        "print(f\"✅ 처리 완료: {OUTPUT_PATH}  (총 {frame_idx} 프레임, {elapsed:.1f}s)\")\n",
        "\n",
        "# === 5) 주석된 MP4를 셀 안에서 즉시 재생(HTML5 video) ===\n",
        "# 코랩은 /content 경로의 파일을 직접 <video>로 재생할 수 있습니다.\n",
        "video_id = str(uuid.uuid4())\n",
        "display(HTML(f\"\"\"\n",
        "<video id=\"{video_id}\" width=\"720\" controls>\n",
        "  <source src=\"{OUTPUT_PATH}\" type=\"video/mp4\">\n",
        "  브라우저가 video 태그를 지원하지 않습니다.\n",
        "</video>\n",
        "<script>\n",
        "  // 자동 재생(무음) 시도: 실패해도 무시\n",
        "  const v = document.getElementById(\"{video_id}\");\n",
        "  v.muted = true;\n",
        "  v.play().catch(()=>{{}});\n",
        "</script>\n",
        "\"\"\"))"
      ],
      "metadata": {
        "id": "zrCAQCWZMJyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 2-2(2-1과 연계)"
      ],
      "metadata": {
        "id": "-uJmTxgpUZeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#객체 추적 라이브러리 설치\n",
        "!pip install -q deep_sort_realtime opencv-python"
      ],
      "metadata": {
        "id": "RC_1KKVZUlF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484fef78-6f67-4666-9d2a-2dcff0e3dff6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/8.4 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/8.4 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m6.3/8.4 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#객체 추적 실행 코드 (YOLOv8 + Deep SORT)\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# Deep SORT 초기화\n",
        "tracker = DeepSort(max_age=30)\n",
        "\n",
        "# 비디오 읽기\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# 비디오 저장용 설정\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('tracked_output.mp4', fourcc, 20.0, (\n",
        "    int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "    int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # YOLOv8 객체 탐지\n",
        "    results = model(frame, verbose=False)[0]\n",
        "\n",
        "    detections = []\n",
        "    for box in results.boxes.data.tolist():\n",
        "        x1, y1, x2, y2, conf, cls = box\n",
        "        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, int(cls)))\n",
        "\n",
        "    # Deep SORT로 객체 추적\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "    # 결과 시각화\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "        track_id = track.track_id\n",
        "        l, t, r, b = map(int, track.to_ltrb())\n",
        "        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f'ID: {track_id}', (l, t - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "fvUhVH_fUpLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm  # 진행상황 출력용\n",
        "\n",
        "# Deep SORT 초기화\n",
        "tracker = DeepSort(max_age=30)\n",
        "\n",
        "# 궤적 저장용\n",
        "trajectories = defaultdict(list)\n",
        "\n",
        "# 비디오 열기\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# 프레임 수 추출 (진행률 표시용)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# 출력 비디오 설정\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('tracked_output1.mp4', fourcc, 20.0, (\n",
        "    int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "    int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "))\n",
        "\n",
        "# tqdm으로 프레임 루프 진행상황 표시\n",
        "for _ in tqdm(range(total_frames), desc=\"처리 중\"):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # YOLOv8 탐지\n",
        "    results = model(frame, verbose=False)[0]\n",
        "\n",
        "    detections = []\n",
        "    for box in results.boxes.data.tolist():\n",
        "        x1, y1, x2, y2, conf, cls = box\n",
        "        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, int(cls)))\n",
        "\n",
        "    # Deep SORT 추적\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "        track_id = track.track_id\n",
        "        l, t, r, b = map(int, track.to_ltrb())\n",
        "        center_x = int((l + r) / 2)\n",
        "        center_y = int((t + b) / 2)\n",
        "\n",
        "        # 궤적 저장\n",
        "        trajectories[track_id].append((center_x, center_y))\n",
        "\n",
        "        # 바운딩 박스 + ID 표시\n",
        "        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f'ID: {track_id}', (l, t - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "        # 궤적 선 그리기\n",
        "        pts = trajectories[track_id]\n",
        "        for j in range(1, len(pts)):\n",
        "            cv2.line(frame, pts[j - 1], pts[j], (0, 0, 255), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "# 종료\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"완료! 추적된 비디오는 'tracked_output1.mp4'로 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "BeMzQSgxUq2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 2-3"
      ],
      "metadata": {
        "id": "i6uoJJ6wXAfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "import cv2\n",
        "\n",
        "# 1. 모델 및 트래커 초기화\n",
        "yolo = YOLO(\"yolov8n.pt\")\n",
        "tracker = DeepSort(max_age=50, n_init=2, nn_budget=100)\n",
        "\n",
        "# 2. 프레임 반복 처리 (간단 예시)\n",
        "frame = cv2.imread(\"scene.jpg\")\n",
        "results = yolo.predict(source=frame, conf=0.25, imgsz=640, verbose=False)[0]\n",
        "\n",
        "# 3. 탐지 정보 변환\n",
        "detections = []\n",
        "for box in results.boxes:\n",
        "    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "    conf = box.conf[0].item()\n",
        "    cls = int(box.cls[0].item())\n",
        "    detections.append(([x1, y1, x2 - x1, y2 - y1], conf, cls, None))\n",
        "\n",
        "# 4. 추적 결과 처리\n",
        "tracks = tracker.update_tracks(detections, frame=frame)\n",
        "for track in tracks:\n",
        "    if not track.is_confirmed(): continue\n",
        "    ltrb = track.to_ltrb()\n",
        "    track_id = track.track_id\n",
        "    cv2.rectangle(frame, (int(ltrb[0]), int(ltrb[1])), (int(ltrb[2]), int(ltrb[3])), (0,255,0), 2)\n",
        "    cv2.putText(frame, f\"ID: {track_id}\", (int(ltrb[0]), int(ltrb[1])-10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
        "\n",
        "cv2.imshow(\"Tracking Improved\", frame)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "WdENixyQXCAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}